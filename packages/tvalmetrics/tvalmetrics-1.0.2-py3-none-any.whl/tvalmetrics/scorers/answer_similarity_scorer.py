import logging

from tvalmetrics.llm_calls import ask_for_similarity_score

logger = logging.getLogger()


class AnswerSimilarityScorer(object):
    """Class for calculating answer similarity score.

    Parameters
    ----------
    model: str
        Name of the LLM model to use as the LLM evaluator.
    """

    def __init__(self, model: str):
        self.model = model

    def score(self, question: str, reference_answer: str, llm_answer: str) -> float:
        """Calculate answer similarity score.

        Parameters
        ----------
        question: str
            The question that was asked.
        reference_answer: str
            The answer that was expected.
        llm_answer: str
            The answer that was generated by the RAG system.

        Returns
        -------
        float
            Float between 0 and 5 representing the answer similarity score.
        """
        similarity_score_response = ask_for_similarity_score(
            question, reference_answer, llm_answer, self.model
        )
        try:
            similarity_score = float(similarity_score_response)
        except ValueError:
            error_message = (
                f"Failed to parse similarity score {similarity_score} as "
                "float, setting score to 0.0"
            )
            logger.error(error_message)
            similarity_score = 0.0

        return similarity_score
