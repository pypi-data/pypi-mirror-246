Metadata-Version: 2.1
Name: sciphi-synthesizer
Version: 1.0.0
Summary: Synthesizer: A Framework for LLM Powered Data.
License: Apache-2.0
Author: Owen Colegrove
Author-email: owen@sciphi.ai
Requires-Python: >=3.9,<3.12
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Provides-Extra: all
Provides-Extra: all-with-extras
Provides-Extra: anthropic-support
Provides-Extra: hf-support
Provides-Extra: vllm-support
Requires-Dist: accelerate (>=0.23.0,<0.24.0) ; extra == "hf-support" or extra == "vllm-support" or extra == "all" or extra == "all-with-extras"
Requires-Dist: anthropic (>=0.3.10,<0.4.0) ; extra == "anthropic-support" or extra == "all" or extra == "all-with-extras"
Requires-Dist: blingfire (>=0.1.8,<0.2.0)
Requires-Dist: datasets (>=2.14.5,<3.0.0) ; extra == "hf-support" or extra == "all" or extra == "all-with-extras"
Requires-Dist: fire (>=0.5.0,<0.6.0)
Requires-Dist: openai (==0.27.8)
Requires-Dist: pyyaml (>=6.0.1,<7.0.0)
Requires-Dist: retrying (>=1.3.4,<2.0.0)
Requires-Dist: tqdm (>=4.66.1,<5.0.0)
Requires-Dist: transformers (>=4.33.1,<5.0.0) ; extra == "hf-support" or extra == "all" or extra == "all-with-extras"
Requires-Dist: vllm (==0.2.0) ; extra == "vllm-support" or extra == "all-with-extras"
Description-Content-Type: text/markdown

# Synthesizer[Î¨Î¦]: A multi-purpose LLM framework ðŸ’¡

<p align="center">
<img width="716" alt="SciPhi Logo" src="https://github.com/emrgnt-cmplxty/sciphi/assets/68796651/195367d8-54fd-4281-ace0-87ea8523f982">
</p>

With Synthesizer, users can:

- **Custom Data Creation**: Generate datasets via LLMs that are tailored to your needs.
   - Anthropic, OpenAI, vLLM, and HuggingFace.
- **Retrieval-Augmented Generation (RAG) on Demand**: Built-in RAG Provider Interface to anchor generated data to real-world sources. 
   - Turnkey integration with Agent Search API. 
- **Custom Data Creation**: Generate datasets via LLMs that are tailored to your needs, for LLM training, RAG, and more.

---

## Documentation

For more detailed information, tutorials, and API references, please visit the official [Synthesizer Documentation](https://sciphi.readthedocs.io/en/latest/).

## Fast Setup

```bash
pip install sciphi-synthesizer
```
## Features

### Community & Support

- Engage with our vibrant community on [Discord](https://discord.gg/j9GxfbxqAe).
- For tailored inquiries or feedback, please [email us](mailto:owen@sciphi.ai).


### Example

The following example demonstrates how to construct a connection to the AgentSearch API with the synthesizer RAG interface. Then, the example goes on to use the RAG interface to generate a response with an OpenAI hosted LLM.

```python

   from synthesizer.core import LLMProviderName, RAGProviderName
   from synthesizer.interface import (
      LLMInterfaceManager,
      RAGInterfaceManager,
   )
   from synthesizer.llm import GenerationConfig

   # RAG Provider Settings
   rag_interface = RAGInterfaceManager.get_interface_from_args(
      RAGProviderName(rag_provider_name),
      api_base=rag_api_base,
      limit_hierarchical_url_results=rag_limit_hierarchical_url_results,
      limit_final_pagerank_results=rag_limit_final_pagerank_results,
   )
   rag_context = rag_interface.get_rag_context(query)

   # LLM Provider Settings
   llm_interface = LLMInterfaceManager.get_interface_from_args(
      LLMProviderName(llm_provider_name),
   )

   generation_config = GenerationConfig(
      model_name=llm_model_name,
      max_tokens_to_sample=llm_max_tokens_to_sample,
      temperature=llm_temperature,
      top_p=llm_top_p,
      # other generation params here ...
   )

   formatted_prompt = rag_prompt.format(rag_context=rag_context)
   completion = llm_interface.get_completion(
      formatted_prompt, generation_config
   )
   print(completion)
```

