{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e7151d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nida\\anaconda3\\envs\\nunit\\lib\\site-packages\\elephant\\parallel\\__init__.py:47: UserWarning: mpi4py package is missing. Please run 'pip install mpi4py' in a terminal to activate MPI features.\n",
      "  warnings.warn(\"mpi4py package is missing. Please run 'pip install mpi4py' \"\n"
     ]
    }
   ],
   "source": [
    "import neo\n",
    "from networkunit import tests, scores, models\n",
    "#from networkunit.capabilities.cap_ProducesSpikeTrains import ProducesSpikeTrains\n",
    "from networkunit.capabilities.ProducesSpikeTrains import ProducesSpikeTrains # branch v0.2\n",
    "from copy import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import elephant\n",
    "import quantities as pq\n",
    "import sciunit\n",
    "from quantities import ms\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4c8fe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_class(path):\n",
    "    \"\"\"\n",
    "    This function creates a model class for the specific file path given.\n",
    "    \"\"\"\n",
    "    class model(models.loaded_spiketrains): \n",
    "    \n",
    "        default_params = {'file_path':path}\n",
    "\n",
    "        def load(self):\n",
    "            file_path = self.default_params['file_path']        \n",
    "            data = pd.read_csv(file_path,skiprows=2,sep='\\t')\n",
    "            spike_data = data.sort_values(by='time_ms')\n",
    "            grouped = spike_data.groupby(spike_data['sender'])\n",
    "\n",
    "            spike_trains = []\n",
    "            for name, group in grouped:\n",
    "                    \"\"\"\n",
    "                    Each group is senders and times for one value of senders. That is, we iterate through all \n",
    "                    neurons. And the times for each neuron is in sorted order. Therefore, the cvs\n",
    "                    returned must have the same order. So cvs contain cv of neuron 1, then neuron 2 .... then neuron N.\n",
    "                    \"\"\"\n",
    "                    t = np.asarray(group['time_ms'])\n",
    "                    spiketrain = neo.core.SpikeTrain(t * pq.ms, t_start=0*pq.ms, t_stop=10000*pq.ms)\n",
    "                    spike_trains.append(spiketrain)\n",
    "            return spike_trains\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f84b5911",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "hasattr(): attribute name must be string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m cont_1 \u001b[38;5;241m=\u001b[39m create_class(cont_seed_1)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# create instance of class\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m cont \u001b[38;5;241m=\u001b[39m \u001b[43mcont_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# produce spike trains\u001b[39;00m\n\u001b[0;32m      6\u001b[0m cont\u001b[38;5;241m.\u001b[39mproduce_spiketrains()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nunit\\lib\\site-packages\\networkunit-0.2.dev0-py3.9.egg\\networkunit\\models\\loaded_spiketrains.py:35\u001b[0m, in \u001b[0;36mloaded_spiketrains.__init__\u001b[1;34m(self, name, backend, attrs, **params)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m----------\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m    class attributes to be stored in self.params\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28msuper\u001b[39m(loaded_spiketrains, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m     33\u001b[0m                                          backend\u001b[38;5;241m=\u001b[39mbackend,\n\u001b[0;32m     34\u001b[0m                                          attrs\u001b[38;5;241m=\u001b[39mattrs)\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams}\n",
      "\u001b[1;31mTypeError\u001b[0m: hasattr(): attribute name must be string"
     ]
    }
   ],
   "source": [
    "cont_seed_1 = 'C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\organized_spike_data\\\\resolution_1_8\\\\brunel_continuous\\\\brunel_continuous_delay_1.0_2.0_seed_1_spikes_exc-12502-0.dat'\n",
    "cont_1 = create_class(cont_seed_1)\n",
    "# create instance of class\n",
    "cont = cont_1()\n",
    "# produce spike trains\n",
    "cont.produce_spiketrains();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eafcb54e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "hasattr(): attribute name must be string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m d2_1 \u001b[38;5;241m=\u001b[39m create_class(d2_seed_1)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# create instance of class\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m droop_1_2 \u001b[38;5;241m=\u001b[39m \u001b[43md2_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# produce spike trains\u001b[39;00m\n\u001b[0;32m      6\u001b[0m droop_1_2\u001b[38;5;241m.\u001b[39mproduce_spiketrains()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nunit\\lib\\site-packages\\networkunit-0.2.dev0-py3.9.egg\\networkunit\\models\\loaded_spiketrains.py:35\u001b[0m, in \u001b[0;36mloaded_spiketrains.__init__\u001b[1;34m(self, name, backend, attrs, **params)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m----------\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m    class attributes to be stored in self.params\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28msuper\u001b[39m(loaded_spiketrains, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m     33\u001b[0m                                          backend\u001b[38;5;241m=\u001b[39mbackend,\n\u001b[0;32m     34\u001b[0m                                          attrs\u001b[38;5;241m=\u001b[39mattrs)\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams}\n",
      "\u001b[1;31mTypeError\u001b[0m: hasattr(): attribute name must be string"
     ]
    }
   ],
   "source": [
    "d2_seed_1 = 'C:\\\\Users\\\\Nida\\\\Documents\\\\NMBU\\\\master\\\\organized_spike_data\\\\resolution_1_2\\\\brunel_rounding_1_2\\\\brunel_rounding_True_delay_1.0_2.0_seed_1_spikes_exc-12502-0.dat'\n",
    "d2_1 = create_class(d2_seed_1)\n",
    "# create instance of class\n",
    "droop_1_2 = d2_1()\n",
    "# produce spike trains\n",
    "droop_1_2.produce_spiketrains();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc5f12b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cont.spiketrains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "433c3799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(droop_1_2.spiketrains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bdd2c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FR_test_class(sciunit.TestM2M, tests.firing_rate_test):\n",
    "    score_type = scores.wasserstein_distance\n",
    "    \n",
    "FR_test = FR_test_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97812272",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "wasserstein_distance.compute failed: 'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\nunit\\lib\\site-packages\\sciunit\\tests.py:729\u001b[0m, in \u001b[0;36mTestM2M.compute_score\u001b[1;34m(self, prediction1, prediction2)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 729\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nunit\\lib\\site-packages\\networkunit-0.2.dev0-py3.9.egg\\networkunit\\scores\\wasserstein_distance.py:31\u001b[0m, in \u001b[0;36mwasserstein_distance.compute\u001b[1;34m(self, observation, prediction, norm, **kwargs)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mCalculates the Wasserstein distance (Earth mover's distance) between\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03mtwo point clouds. Uses the opencv implementation in the backend and can\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m \n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mobservation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m prediction\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m     32\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m observation\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mFR_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjudge\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcont\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdroop_1_2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nunit\\lib\\site-packages\\sciunit\\tests.py:955\u001b[0m, in \u001b[0;36mTestM2M.judge\u001b[1;34m(self, models, skip_incapable, stop_on_error, deep_error, only_lower_triangle)\u001b[0m\n\u001b[0;32m    953\u001b[0m     scores[i][j] \u001b[38;5;241m=\u001b[39m scores[j][i]\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 955\u001b[0m     scores[i][j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_judge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel2\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scores[i][j], ErrorScore) \u001b[38;5;129;01mand\u001b[39;00m stop_on_error:\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m scores[i][j]\u001b[38;5;241m.\u001b[39mscore  \u001b[38;5;66;03m# An exception.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nunit\\lib\\site-packages\\sciunit\\tests.py:800\u001b[0m, in \u001b[0;36mTestM2M._judge\u001b[1;34m(self, prediction1, prediction2, model1, model2)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;124;03m\"\"\"Generate a score to compare the predictions by the models.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m \n\u001b[0;32m    784\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;124;03m    Score: A sciunit score instance.\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;66;03m# TODO: Not sure if below statement is required\u001b[39;00m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;66;03m# self.last_model = model\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \n\u001b[0;32m    799\u001b[0m \u001b[38;5;66;03m# 6.\u001b[39;00m\n\u001b[1;32m--> 800\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverter:\n\u001b[0;32m    802\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverter\u001b[38;5;241m.\u001b[39mconvert(score)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nunit\\lib\\site-packages\\sciunit\\tests.py:732\u001b[0m, in \u001b[0;36mTestM2M.compute_score\u001b[1;34m(self, prediction1, prediction2)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    731\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.compute failed: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mstr\u001b[39m(e))\n\u001b[1;32m--> 732\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(msg)\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "\u001b[1;31mException\u001b[0m: wasserstein_distance.compute failed: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "scores = FR_test.judge([cont,droop_1_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee89429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
