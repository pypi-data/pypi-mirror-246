def make(int1):
    if (int1==1):
        print("import numpy as np \nimport pandas as pd\nimport pandas as pd\ndf = pd.read_csv('Salary.csv')\nprint(df.to_string())\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nX = df.iloc[:, :-1].values    # Features => Years of experience => Independent Variable\ny = df.iloc[:, -1].values     # Target => Salary => Dependent Variable\nX\nfrom sklearn.model_selection import train_test_split\nimport sklearn.metrics as sm\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\nfrom sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\npredictions = model.predict(X_test)\nimport seaborn as sns\nsns.distplot(predictions-y_test)\nplt.scatter(X_train, y_train, color='red')\nplt.plot(X_train, model.predict(X_train))\nr_sq = model.score(X_train, y_train)\nprint('coefficient of determination:', r_sq)\nprint('intercept:', model.intercept_)\nprint('slope:', model.coef_) \ny_pred = model.predict(X_train)\nprint('y='+str(float(model.coef_))+'X+'+str(float(model.intercept_)))\n")
    elif(int1==2):
        print("import pandas as pd\ndf = pd.read_csv('wine-clustering.csv')\ndf.head()\ndf.describe().T\ndf.info()\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.pairplot(df)\nfrom sklearn.cluster import KMeans\nselected_features = df[['OD280', 'Alcohol']]\nkmeans_obj = KMeans(n_clusters=3, random_state=42) \nkmeans_obj.fit(selected_features)\ny_kmeans = kmeans_obj.fit_predict(selected_features)\nprint(y_kmeans)\ncenters = kmeans_obj.cluster_centers_\nprint(centers)\nsns.scatterplot(x = selected_features['OD280'], y = selected_features['Alcohol'], hue=kmeans_obj.labels_)\nplt.scatter(kmeans_obj.cluster_centers_[:, 0], kmeans_obj.cluster_centers_[:, 1], s=200, c='red')\n")
    elif(int1==3):
        print("import numpy as np\nimport pandas as pd\ndata = pd.read_csv('breast-cancer-wisconsin-data_data.csv')\ndata.head()\ndata.columns\ndata = data.drop(['id', 'Unnamed: 32'], axis = 1)\ndata.shape\ndata.describe()\ndata.info()\ndata.columns\nX = data.loc[:, ['radius_mean', 'texture_mean', 'perimeter_mean','area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean','concave points_mean', 'symmetry_mean', 'fractal_dimension_mean','radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se','compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se','fractal_dimension_se', 'radius_worst', 'texture_worst','perimeter_worst', 'area_worst', 'smoothness_worst','compactness_worst', 'concavity_worst', 'concave points_worst','symmetry_worst', 'fractal_dimension_worst']]\ny = data.loc[:, 'diagnosis']\nX.head()\ny.head()\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nfrom sklearn.neighbors import KNeighborsClassifier\nknn_cfr = KNeighborsClassifier(n_neighbors=3)\nknn_cfr.fit(X_train, y_train)\ny_pred = knn_cfr.predict(X_test)\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred)\n")
    elif(int1==4):
        print("import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndata = pd.read_csv('kc_house_data.csv')\ndata.head()\ndata  = data.drop(['id', 'date'], axis = 1)\ndata.head()\ndata.describe()\ndata['bedrooms'].value_counts().plot(kind='bar')\nplt.title('number of Bedroom')\nplt.xlabel('Bedrooms')\nplt.ylabel('Count')\nsns.despine()\nplt.figure(figsize=(10,10))\nsns.jointplot(x=data.lat.values, y=data.long.values, height=10)\nplt.ylabel('Longitude',fontsize=12)\nplt.xlabel('Latitude',fontsize=12)\nsns.despine()\nplt.show()\nplt.scatter(data.price,data.sqft_living)\nplt.title('Price vs Square Feet')\nplt.scatter(data.price,data.long)\nplt.title('Price vs Location of the area')\nplt.scatter(data.price,data.lat)\nplt.xlabel('Price')\nplt.ylabel('Latitude')\nplt.title('Latitude vs Price')\nplt.scatter(data.bedrooms,data.price)\nplt.title('Bedroom and Price ')\nplt.xlabel('Bedrooms')\nplt.ylabel('Price')\nsns.despine()\nplt.show()\nplt.scatter((data['sqft_living']+data['sqft_basement']),data['price'])\nplt.scatter(data.waterfront,data.price)\nplt.title('Waterfront vs Price ( 0= no waterfront)')\ny = data['price']\nX = data.drop(['price'],axis=1)\nfrom sklearn.model_selection import train_test_split\nx_train , x_test , y_train , y_test = train_test_split(X , y , test_size = 0.10,random_state =2)\nfrom sklearn.linear_model import LinearRegression\nreg = LinearRegression()\nreg.fit(x_train,y_train)\nreg.score(x_test,y_test)\n")
    elif(int1==5):
        print("import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\ndf = pd.read_csv('adult.csv')\ndf.head()\ndf.columns\ndf.shape\ndf.isin(['?']).sum()\ndf['workclass'] = df['workclass'].replace('?', np.nan)\ndf['occupation'] = df['occupation'].replace('?', np.nan)\ndf['native-country'] = df['native-country'].replace('?', np.nan)\ndf.isin(['?']).sum()\ndf.isnull().sum()\ndf.dropna(how='any', inplace=True)\nprint(f'There are {df.duplicated().sum()} duplicate values')\ndf = df.drop_duplicates()\ndf.shape\ndf.columns\ndf.drop(['fnlwgt','educational-num','marital-status','relationship', 'race',], axis = 1, inplace = True)\ndf.columns\nX = df.loc[:,['age', 'workclass', 'education', 'occupation', 'gender', 'capital-gain','capital-loss', 'hours-per-week', 'native-country']]\ny = df.loc[:,'income']\nX.head()\ny.head()\nfrom sklearn.preprocessing import LabelEncoder\ny = LabelEncoder().fit_transform(y)\ny = pd.DataFrame(y)\ny.head()\nnumeric_features = X.select_dtypes('number')\ncategorical_features = X.select_dtypes('object')\ncategorical_features\nnumeric_features\nconverted_categorical_features = pd.get_dummies(categorical_features)\nconverted_categorical_features.shape\nall_features = [converted_categorical_features, numeric_features]\nnewX = pd.concat(all_features,axis=1, join='inner')\nnewX.shape\nnewX.columns\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(newX, y, test_size=0.33, random_state=42)\nfrom sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier(max_depth=5)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\ny_test.shape\ny_pred.shape\npredictions_df = pd.DataFrame()\npredictions_df['precdicted_salary_class'] = y_pred\npredictions_df['actual_salary_class'] = y_test[0].values\npredictions_df\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(y_pred,y_test))\nfrom sklearn.tree import plot_tree\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(14,14))\nplot_tree(clf, fontsize=10, filled=True)\nplt.title('Decision tree trained on the selected features')\nplt.show()\n")
    elif(int1==6):
        print("import numpy as np\nimport pandas as pd\ndf = pd.read_csv('smaller_adult.csv')\ndf.head()\ndf.columns\ndf.shape\ndf.info()\ndf.describe()\ndf.isin(['?']).sum()\ndf.columns\ndf['workclass'] = df['workclass'].replace('?', np.nan)\ndf['occupation'] = df['occupation'].replace('?', np.nan)\ndf.isin(['?']).sum()\ndf.isnull().sum()\ndf.dropna(how='any', inplace=True)\nprint(f'There are {df.duplicated().sum()} duplicate values')\ndf = df.drop_duplicates()\ndf.shape\ndf.columns\nX = df.loc[:,['age', 'workclass', 'educational-num', 'occupation', 'gender', 'hours-per-week']]\ny = df.loc[:,'income']\nfrom sklearn.preprocessing import LabelEncoder\ny = LabelEncoder().fit_transform(y)\ny = pd.DataFrame(y)\ny.head()\nnumeric_features = X.select_dtypes('number')\ncategorical_features = X.select_dtypes('object')\ncategorical_features\nnumeric_features\nconverted_categorical_features = pd.get_dummies(categorical_features)\nconverted_categorical_features.shape\nall_features = [converted_categorical_features, numeric_features]\nnewX = pd.concat(all_features,axis=1, join='inner')\nnewX.shape\nnewX.columns\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(newX, y, test_size=0.33, random_state=42)\nfrom sklearn.svm import SVC\nclf = SVC(kernel='linear', gamma = 'auto')\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\npredictions_df = pd.DataFrame()\npredictions_df['precdicted_salary_class'] = y_pred\npredictions_df['actual_salary_class'] = y_test[0].values\npredictions_df\nfrom sklearn.metrics import accuracy_score\nprint(accuracy_score(y_pred,y_test))\n")
    elif(int1==7):
        print("import numpy as np\nimport pandas as pd\ndf = pd.read_csv('breast-cancer-wisconsin-data_data.csv')\ndf.head()\ndf.shape\ndf = df.drop(['id', 'Unnamed: 32'], axis = 1)\ndf.columns\ndf.describe()\ndf.info()\nX = df.loc[:, ['radius_mean', 'texture_mean', 'perimeter_mean','area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean','concave points_mean', 'symmetry_mean', 'fractal_dimension_mean','radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se','compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se','fractal_dimension_se', 'radius_worst', 'texture_worst','perimeter_worst', 'area_worst', 'smoothness_worst','compactness_worst', 'concavity_worst', 'concave points_worst','symmetry_worst', 'fractal_dimension_worst']]\ny = df.loc[:, 'diagnosis']\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nfrom sklearn.neural_network import MLPClassifier\nclf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, y_train)\ny_pred = clf.predict(X_test)\ny_pred\nfrom sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred)\n")
    elif(int1==8):
        print("from sklearn.datasets import load_iris\nfrom sklearn.datasets import load_diabetes\nfrom sklearn import metrics\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\niris = load_iris()\nX = iris.data\ny = iris.target\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\ngnb = GaussianNB()\ngnb.fit(X_train, y_train)\ny_pred = gnb.predict(X_test)\nfrom sklearn import metrics\nprint('Gaussian Naive Bayes model accuracy(in %):', metrics.accuracy_score(y_test, y_pred)*100)\n")
    elif(int1==9):
        print("import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import GaussianNB\nnames = ['K-Nearest Neighbors','Linear SVM','Decision Tree','Multilayer Perceptron','Gaussian Naive Bayes']\nclassifiers = [KNeighborsClassifier(3),SVC(kernel='linear', C=0.025),DecisionTreeClassifier(max_depth=5),MLPClassifier(alpha=1, max_iter=1000),GaussianNB(),]\ndf = pd.read_csv('Iris.csv')\ndf.head()\ndf = df.drop('Id', axis = 1)\ndf.head()\nX= df.iloc[:, :-1]\nX.head()\ny = df.iloc[:, -1]\ny.head()\nfrom sklearn.preprocessing import LabelEncoder\ny = LabelEncoder().fit_transform(y)\ny = pd.DataFrame(y)\ny.head()\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nfor name, clf in zip(names, classifiers):\n    clf.fit(X_train, y_train.values.ravel())\n    score = clf.score(X_test, y_test)\n    print('Classifier Name: ', name, 'Score: ',  score)\n")
    elif(int1==10):
        print("import pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense\ndf = pd.read_csv('BankNote_Authentication.csv')\ndf.head()\nX = df.values[:, :-1]\ny = df.values[:, -1]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\nmodel = Sequential()\nmodel.add(Dense(7, input_shape=(X.shape[1],)))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(optimizer='adam',loss='binary_crossentropy')\nmodel.fit(X_train, y_train, epochs=30, batch_size=32)\ny_pred = model.predict(X_test)\ny_pred\ny_pred = (y_pred>0.5).flatten().astype(int)\ny_pred\nprint(accuracy_score(y_test, y_pred))\n")
    
def list():
    print("1.linear regression\n2.kmeans\n3.knn\n4.housePriceLinear regression\n5.decision tree\n6.svm\n7.perceptron\n8.nbc\n9.comparision\n10.tensor flow")




