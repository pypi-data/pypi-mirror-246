#!/usr/bin/env python
"""
We receive msgs from WebSocketApp:
                                     -> stream pipeline[flow] -
    msg -> msg._ws = ws -> subj_rcv                              -> subj_send 
                                     -> stream func_calls[func] -


    
msg: 
    type: register|msg|response
    _ws: websock
    _ids:
       hbn: hub name (used for routing to it)
       hub: hub as we see it (we use host port currently, *should* be unique, metrics group on that)
       sck: websock id (generated )
       trn: transaction (short term, short term persistent state, determines long term db writes )
       msg: message id, as generated by nr
       cln: client name (*should* be unique)
       pid: client process id
       sid: session id (determines routing, may live forever)
       nod: opperator id, id of corresponding NR box if corresponding
       flw: flow id = nod, node.id of the entry node. NOT NR's flow.id

    payload:
       [body]: string, e.g. xml, converted, enriched during proc.

    _req: forwarded if custom processor
    _resp: not forwarded, but enrichable


All operators get their metrics id: hub name + node.id and do their own metrics


For routing into the py process we go hid->wid, thats what we put e.g. into a routing cookie

Resilience for process restarts:
    The other side, when sck is gone will buffer and wait for hub or cln. Must be configurable.


Handshake

For all servers:

client --> server: ws open
server --> client: type: register
                   _ids={'sck': 'ax-niyz98wi-x0alhvi7', 'hbn': 'hub1'}
                   payload={'pipelines': {'ax-op-1': [{'nod': 'ax-op-1'...
(client builds pipelines (streams))
client --> server: type: register
                   cln: 
                   payload: funcs: math:mult, ..

(server puts into AH.clients, now knows what funcs client supports)



"""

import os
import random
import socket
import time
from functools import partial as p

import gevent
import rx
import websocket
from devapp.app import app
from devapp.tools import FLG, define_flags, failsafe, offset_port, read_file
from node_red import nr_config_builder, tools
from operators.ctrl.client import subscribe_to_ctrl_broadcasts

from operators import build, list_ops
from operators.const import ax_pipelines
from operators.core import decode_msg, encode_msg
from operators.ops.funcs import Funcs, build_funcs_tree, funcs_pretty
from rx import operators
from rx.scheduler.eventloop import GEventScheduler

Rx = rx
rx = operators  # => rx.map, not op.map...

js, jp = tools.js, tools.jp


class flags:
    autoshort = 'lc'
    short_maxlen = 5

    class list_ops:
        n = 'Show the available operators in this client installation'
        d = False

    class lc_client_name:
        n = 'Client Name'
        d = 'axclient'

    class lc_flow:
        n = 'Configure Node RED with this flow at time of connect.'
        n += 'Note: client may be programmatically sending a flow, via a connect parameter.\n'
        n += 'Can be a file containing a flow or a serialized json directly or a keyword:\n'
        n += '- Set lc_flow to "hub" to ignore that temporary(?) any only accept and run flow from a hub.\n'
        n += '- Set lc_flow to "funcs" to use a flow=[..] parameter within your function tree root.'

    class lc_autonomous:
        n = 'Run given flow without node red'
        d = None

    class lc_hubs:
        n = 'Node RED servers (we connect to port +1). Tip: "127.0.0.1:" may be omitted.'
        d = '127.0.0.1:1880'
        t = list

    class lc_hub_recon_intv:
        n = 'Hub reconnect interval in sec (how often we retry when a hub is lost)'
        d = 1

    class lc_tabs:
        n = 'Restrict pipeline building to operators on given tabs only. List the tab labels you want kept - not the ids. "!" negates.'
        d = ''
        t = list

    class log_debug_payload_max_len:
        n = 'Cutoff length for payload logging when not matching'
        d = 20

    class log_debug_full_payload_match:
        n = 'When payload should be logged fully at debug log level'
        d = '<no match>'

    class client_functions:
        n = 'Client function tree. Default: AX core operators only. E.g. mymod.MyFuncs'
        d = ''


define_flags(flags)
# we don't nest partials but just the data:
host = socket.gethostname()
log_kws = {'pid': os.getpid(), 'host': host}


def setup_log(kw, frm_kw, into):
    m = dict(frm_kw)
    m.update(kw)
    into.dbg = p(app.debug, **m)
    into.info = p(app.info, **m)
    into.warn = p(app.warn, **m)
    into.error = p(app.error, **m)


run = Rx.Observable.run

conc = {'msg_counter': -1}
max_concurrent = 10


GS = GEventScheduler(gevent)
hubs = {}
subs = {}


def t(r):
    """trace"""
    print(r)
    breakpoint()
    return r


# def msg_to_r(msg):
#     r = msg.pop('payload')
#     if isinstance(r, str):
#         r = {'payload': r}
#     r['msg'] = msg
#     return r


# def r_to_msg(r):
#     msg = r.pop('msg')
#     msg['payload'] = r.get('body', r)
#     return msg


# def response(msg, wait=0):
#     """send back to original client. requires session"""
#     r = r_to_msg(dict(msg))
#     hp = r['hp']
#     ws = hubs[hp]['ws']
#     send(ws, r)


# def call_msg_handler(msg):
#     ws = hubs[msg['hp']]['ws']
#     typ = msg['type']
#     func = getattr(MsgHandlers, 'on_' + typ, noop)
#     try:
#         msg['payload'] = func(msg, ws)
#     except Exception as ex:
#         exc_type, exc_value, exc_tb = sys.exc_info()
#         tb = traceback.format_exception(exc_type, exc_value, exc_tb)
#         print(str(tb))
#         msg['err'] = str(ex)
#         msg['err_details'] = {'tb': tb}
#     send(ws, msg)
#     ws.dbg('returned', **msg)
#     return msg

uri = '/ws/ax-hub'


class WebSocket(websocket.WebSocketApp):
    wid = None  # at register

    def __init__(self, host, port, uri, subj_rcv):
        self.subj_rcv = subj_rcv
        self.hub_sck_name = None
        self.hp = hp = (host, port)
        self.url = 'ws://%s:%s%s' % (host, port, uri)
        (app.debug if FLG.lc_autonomous else app.info)('creating hub ws', url=self.url)
        hubs[tuple(hp)] = {'status': 'init', 'ws': self}
        super().__init__(
            self.url,
            on_close=self.on_close,
            on_open=self.on_open,
            # for binary transfer we do not use on_data but stay with on_message plus on_cont_message for long ones.
            # see _app.py of the library how they callback.
            on_message=self.on_message,
            on_cont_message=self.on_cont_message,
        )

    def __repr__(self):
        return self.url

    __str__ = __repr__

    def __iter__(self):
        """
        We don't need iterating over - but this kills ujson.dumps, which blocks:
        (and we are in any msg as msg['_ws'])
        """
        yield None

    def on_open(self):
        self.subj_rcv.on_next({'_ws': self, 'type': 'wsopen'})

    def set_close_status(self):
        if not hubs[self.hp]['status'] == 'close_requested':
            hubs[self.hp]['status'] = 'closed'

    def on_close(self):
        # maybe no warn when not yet registered, so fallback:
        level, lg = 'warn', app.warn
        if FLG.lc_autonomous:
            level, lg = 'debug', app.debug
        # try except wrapped, avoids logging problems
        log = getattr(self, level, lg)
        call_safe(log, 'closing hub ws', url=self.url, sock=sockstr(self))
        call_safe(self.set_close_status)
        # only this triggers the ws.close callback on the hub:
        if self.sock:
            self.sock.shutdown()
        call_safe(log, 'closed', url=self.url, sock=sockstr(self))

    def on_message(self, data):
        msg = decode_msg(data)
        if msg.get('payload') is None:
            app.warn('no payload', **msg)
            return
        msg['_ws'] = self
        payload_log(app, msg, 'H -> C: ')
        hubs[self.hp]['status'] = 'alive'
        typ = msg['type'] = msg['type']
        self.subj_rcv.on_next(msg)

    def on_cont_message(self, data, fin=None):
        """"""
        breakpoint()  # FIXME BREAKPOINT


def call_safe(f, *a, **kw):
    # to avoid crashing when writing logs after tests and I/O is gone
    try:
        f(*a, **kw)
    except Exception:
        pass


def sockstr(ws):
    if ws.sock is None:
        return '[None]'
    try:
        return str(ws.sock.sock)
    except Exception as ex:
        return 'No sock: %s' % str(ex)


def noop(*a, **kw):
    return 0


def client_status(msg):
    msg['payload'] = {
        'pipes': build.ax_pipelines['pipes'],
    }
    return msg


def build_pipelines(flow, subscribe=None, dyn_snk_types=None, dyn_snks=None):
    def ext_out(msg, operator):
        """The method every msg sees before going out to NR"""
        # last_op is super important on the hub: hub will call node.send(msg) on it:
        msg['_ids']['last_op'] = operator['id']
        subj_snd.on_next(msg)

    try:
        axp = build.build_pipelines(flow, ext_out=ext_out, dyn_snk_types=dyn_snk_types)
    except Exception as ex:
        app.error('BUILD ERROR - RESETTING BUILD')
        axp = build.build_pipelines(
            [{'id': 'error', 'name': 'build err', 'type': 'tab'}],
            ext_out=ext_out,
            dyn_snk_types=dyn_snk_types,
        )
        app.error(
            'Could not build pipelines, - fix your flow!'.upper(),
            hint='Study build warnings and errors listed above and fix top down.',
            exc=ex,
        )
        axp = False
        # build.subscribe_many(mode='unsubscribed')

    if axp is False:
        # not rebuilt:
        axp = ax_pipelines
    # subs['err'] = axp['rxerrors'].subscribe(lambda exc: report_err(exc))
    elif subscribe:
        k = 'on_init'
        # initializer present?
        i = Funcs.get(k)
        d = 'done_' + k
        if i and not i.get(d):
            app.info('Calling hook', hook=k)
            i['func']()
            if k == 'on_init':
                i[d] = True
        build.subscribe_many(dyn_snk_status=dyn_snks)
        k = 'on_subscribed'
        i = Funcs.get(k)
        if i:
            app.info('Calling hook', hook=k)
            i['func']()

    return axp


class ProcessRcv:
    """Per msg[type], as from NR,
    - Run in sep greenlet
    - Will normally invode functions which .next on subj_send, for responses to NR
    - May also directly return data to send
    """

    def wsopen(msg):
        app.info('open', ws=msg['_ws'])

    def status(msg):
        msg['_ws'].hub_sck_name = msg['payload']['registered']
        # for whoever is interested:
        subj_sts.on_next(msg)
        return client_status(msg)

    def register(msg):
        nr_flow = msg['payload']['pipelines']['flows']
        cli_flow = FLG.lc_flow

        if cli_flow and cli_flow not in (nr_flow, 'hub'):
            msg['type'] = 'flow_def'
            msg['payload'] = {'flows': nr_config_builder.escaped_flow(cli_flow)}
            return msg

        ids, ws = msg['_ids'], msg['_ws']
        ids['hub'] = '%s:%s' % ws.hp
        setup_log(ids, frm_kw=log_kws, into=ws)
        [setattr(ws, k, v) for k, v in ids.items()]
        hp = msg['_ws'].hp

        p = msg['payload']
        F = p['pipelines']['flows']

        tabs = FLG.lc_tabs
        if tabs:
            all_tabs_by_id = {f['id']: f['label'] for f in F if f.get('type') == 'tab'}
            all_subfl_ids = {f['id'] for f in F if f.get('type') == 'subflow'}
            our_tab_ids = set()
            have_positives = any([lab for lab in tabs if not lab.startswith('!')])
            for id, lab in all_tabs_by_id.items():
                if '!' + lab in tabs:
                    continue
                if not have_positives or lab in tabs:
                    our_tab_ids.add(id)

            ol = len(F)

            def in_tab(node):
                if node.get('type') == 'tab' and node['id'] not in our_tab_ids:
                    return
                z = node.get('z')
                if not z or z in our_tab_ids or z in all_subfl_ids:
                    return True

            F = [node for node in F if in_tab(node)]
            if ol != len(F):
                app.info('Filtered out operators', tabs_filter=tabs, had=ol, kept=len(F))
        subscribe_to_ctrl_broadcasts()  # out of pipeline messages from hub, ususally sent from ctrl worker
        axp = build_pipelines(
            F,
            subscribe=True,
            dyn_snk_types=p['dyn_snk_types'],
            dyn_snks=p['dyn_snks'],
        )

        msg['payload'] = {
            'funcs': funcs_pretty(Funcs),
            'cln': FLG.lc_client_name,
            'pipes': axp['pipes'],
            'nr_cut_wires': axp['nr_cut_wires'],
            'err_build': axp['err_build'],
        }
        return msg

    def broadcast(msg):
        subj_cst.on_next(msg)

    def msg(msg, axp=build.ax_pipelines):
        ser = msg.get('enc')
        ws = msg['_ws']
        flw = msg['_ids'].get('flw')
        subj = axp['nr_sources'].get(flw)
        if subj:
            # hub will register in waiting
            subj.on_next(msg)
            return
        raise Exception('Flow not found', msg)
        # # direct call
        # ws = hubs[msg['hp']]['ws']
        # fnl = list(msg['func'])
        # while fnl:
        #     fn = fnl.pop(0)
        #     func = Funcs.get(fn)
        #     if not func:
        #         raise Exception('Function not found', fn)
        #     res = func(msg['payload'])
        # return res

    def subs_change(msg):
        """A snk, w.g. a wsout was subscribed or unsubscribed to on NR"""
        ws = msg['_ws']
        ws.info('subs change', **msg)
        mode = msg['payload']['mode']
        id = msg['payload']['snk']
        build.subs_change(id, mode)

    def response(msg):
        breakpoint()  # FIXME BREAKPOINT


def type_not_supported(s):
    breakpoint()  # FIXME BREAKPOINT


NS = build.tools.NamedSubject
subj_rcv = NS('rcv')  # all in
subj_snd = NS('snd')  # all out
subj_map = NS('map')  # all func calls
subj_blk = NS('blk')  # all waiting
subj_cnr = NS('cnr')  # counters + data raw out (all operators)
subj_cns = NS('cns')  # counters processed (all operators)
subj_sts = NS('sts')  # all status updates from hub, for interested watchers
subj_cst = NS('cst')  # broadcast messages from NodeRed
# all data flow errors in rxerrors

# stream of all received messages and their processing:


def wsprocessing(subj):
    return subj.pipe(
        rx.group_by(lambda msg: msg.get('type')),
        rx.flat_map(
            lambda s: s.pipe(
                rx.observe_on(GS),
                rx.map(getattr(ProcessRcv, s.key, type_not_supported)),
            )
        ),
        rx.filter(lambda msg: bool(msg)),
    )


s_send = wsprocessing(subj_rcv)


def alive_hubs():
    return list([h for h in hubs.keys() if hubs[h]['status'] == 'alive'])


def find_best_hub(msg):
    """
    for messages which where not originated from a hub we have no ws info
    We currently route randomly
    """
    # FIXME Too slow to do that on ANY(!) message
    l = alive_hubs()
    while l:
        h = hubs[random.choice(l)]
        if h['status'] == 'alive':
            return h['ws']
        l = alive_hubs()


def send(msg):
    if not msg:
        return
    try:
        _send(msg)
    except Exception as ex:
        failsafe(app.error, 'Send Error', exc=ex)


def payload_log(logger, msg, direction):
    if app.log_level > 10:
        return
    m = dict(msg)
    pl = m.pop('payload', '')
    pls = str(pl)
    pll = len(pls)
    m['payload_len'] = pll
    if FLG.log_debug_full_payload_match in pls:
        maxlen = 100000
    else:
        maxlen = FLG.log_debug_payload_max_len
    m['payload_start'] = pls[:maxlen] + ('...' if len(pls) > maxlen else '')
    app.debug(direction + msg.get('type', 'x'), **m)


def _send(msg):
    if msg.get('payload') is None:
        # local snk
        return

    ws = msg.pop('_ws', 0)
    if not ws:
        ws = find_best_hub(msg)
        if not ws:
            app.error('No hub - cannot send', msg=msg['_ids'])
            return
    payload_log(ws, msg, 'C -> H: ')
    m, is_bin = encode_msg(msg)
    try:
        ws.sock.send_binary(m) if is_bin else ws.sock.send(m)
        # this may be just a blocking out-goer -> need keep that ref then:
        msg['_ws'] = ws
    except Exception as ex:
        # can happen e.g. when nr is auto restarted at flow.json change and
        # deploy is pressed, changing it -> closing 2 times!
        # Should we sys.exit and leave it to e.g. systemd to restart us?
        # on_close was seen, so we should be clean at this point - lets try continue
        app.warn('Socket closed!', err=str(ex), failed=msg['type'])


def connect_to_ws_srv(host, port, uri, subj_rcv, hub_recon_intv):
    # wip, no reg. yet, just async:

    def _run(i, h=host, p=port, uri=uri, s=subj_rcv):
        hub = hubs.get((host, port))
        if hub and hub['status'] == 'close_requested':
            return
        ws = WebSocket(h, p, uri, s)
        ws.run_forever()

    # retry loop: The delay is needed in order to avoid instant reconnects:
    stream = Rx.concat(Rx.just(1), Rx.interval(hub_recon_intv, GS)).pipe(
        rx.delay(0.1), rx.map(_run)
    )
    # sub = Rx.just(1).pipe(rx.map(_run))
    d = Subscription('Hub WS (Re)Conn', stream)
    return d


class Subscription:
    """When registering disposables (in subs) we want to see the stream status
    => This is all aobout the __repr__ function
    """

    name = stream = disposable = None

    def __init__(self, name, stream):
        self.name = name
        self.stream = stream
        self.disposable = stream.subscribe(lambda x: x)

    @property
    def is_disposed(self):
        return self.disposable.is_disposed

    def dispose(self):
        self.disposable.dispose()

    def __repr__(self):
        status = 'running' if not self.is_disposed else 'disposed'
        name = self.name
        return f'{name} Stream {status}'


# debug helper:
def sl(f=1):
    time.sleep(f)


def create_hub_comm_streams(hublist, hub_recon_intv):
    app.info('create_comm_streams', hubs=hublist)
    subs['sent'] = subj_snd.subscribe(lambda msg: send(msg))
    subs['processed'] = s_send.subscribe(lambda msg: subj_snd.on_next(msg))

    for h in hublist:
        h = ('127.0.0.1:' + h).rsplit(':')[1:]
        port = offset_port(h[1]) + 1
        i = hub_recon_intv
        subs[tuple(h)] = connect_to_ws_srv(h[0], port, uri, subj_rcv, i)

    while True:
        try:
            time.sleep(10)
        except KeyboardInterrupt as ex:
            build.unsubscribe_many(which='all', clear_pipelines=True)
            close_all()
            app.die('KeyboardInterrupt - bye.', silent=True)


def close_all(stop=False):
    if not hubs:
        return

    for k, v in subs.items():
        app.warn('disposing ', subscription=k)
        v.dispose()
        time.sleep(0)
    for hp, h in hubs.items():
        if stop:
            h['status'] = 'close_requested'
        app.warn('closing ', hub=h)
        h['ws'].close()
        time.sleep(0.01)

    if stop:
        return
    if len(hubs) - len(alive_hubs()) < 10:
        return
    gevent.spawn(hub_closer)


def hub_closer():
    # avoid dead hubs piling up, when this is called too often:
    h = dict(hubs)
    for k in h:
        if h[k]['status'] != 'alive':
            try:
                del hubs[k]
            except Exception as ex:
                pass


def disconnect():
    from operators.ops.funcs import Funcs

    build.unsubscribe_many(which='all', clear_pipelines=True)
    close_all(stop=True)
    hubs.clear()
    Funcs.clear()


def get_hubs_list(hubs=None, c=[0]):
    h = c[0]
    if h:
        return h
    hubs = tools.to_list(hubs or FLG.lc_hubs)
    hubs = c[0] = [f'127.0.0.1:{p}' if p.isdigit() else p for p in hubs]
    return hubs


def connect(
    funcs=None, hubs=None, hub_recon_intv=None, prefix='', flow=None, autonomous=False
):
    """Entrypoint for Clients - They call connect on us with their functions."""
    if FLG.list_ops:
        return list_ops()

    app.info('connect called')
    log_kws['cn'] = FLG.lc_client_name

    build_funcs_tree(funcs or FLG.client_functions)

    hub_recon_intv = hub_recon_intv or FLG.lc_hub_recon_intv

    flow = FLG.lc_flow or flow
    if flow:
        if flow == 'hub':
            FLG.lc_flow = None
        else:
            if flow == 'funcs':
                FLG.lc_flow = None
                try:
                    flow = Funcs['root'].flow
                except Exception as ex:
                    app.die("Funcs tree has not 'flow' attribute.")
            else:
                if isinstance(flow, str):
                    import json

                    if os.path.exists(flow):
                        flow = read_file(flow)

                    flow = json.loads(flow)
            flow = nr_config_builder.nr_config(flow)
            FLG.lc_flow = flow

    if autonomous and FLG.lc_autonomous is None:
        FLG.lc_autonomous = autonomous
    hubs = get_hubs_list(hubs)

    build.unsubscribe_many(which='all', clear_pipelines=True)
    close_all()
    if FLG.lc_autonomous and FLG.lc_flow and FLG.lc_flow != 'hub':
        axp = build_pipelines(FLG.lc_flow, subscribe=True)
    create_hub_comm_streams(hubs, hub_recon_intv)


if __name__ == '__main__':
    pass
