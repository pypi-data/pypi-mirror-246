Metadata-Version: 2.1
Name: scrachy
Version: 0.5.9
Summary: Enhanced caching modules for scrapy.
Home-page: https://bitbucket.org/reidswanson/scrachy
Author: Reid Swanson
Author-email: reid@reidswanson.com
Maintainer: Reid Swanson
Maintainer-email: reid@reidswanson.com
License: lgpl-v3
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: GNU Lesser General Public License v3 or later (LGPLv3+)
Classifier: Natural Language :: English
Classifier: Operating System :: MacOS
Classifier: Operating System :: Microsoft :: Windows
Classifier: Operating System :: POSIX
Classifier: Operating System :: Unix
Classifier: Programming Language :: Python :: 3.11
Description-Content-Type: text/markdown
License-File: LICENSE.md
Requires-Dist: cron-converter
Requires-Dist: msgspec
Requires-Dist: scrapy
Requires-Dist: selenium
Requires-Dist: sqlalchemy
Requires-Dist: twisted
Requires-Dist: w3lib
Requires-Dist: pywin32 ; os_name == "nt"
Provides-Extra: all
Requires-Dist: beautifulsoup4 ; extra == 'all'
Requires-Dist: boilerpy3 ; extra == 'all'
Requires-Dist: html5lib ; extra == 'all'
Requires-Dist: lxml ; extra == 'all'
Requires-Dist: pymysql ; extra == 'all'
Requires-Dist: psycopg2 ; extra == 'all'
Requires-Dist: pytest ; extra == 'all'
Requires-Dist: pytest-twisted ; extra == 'all'
Requires-Dist: python-dotenv ; extra == 'all'
Requires-Dist: pyyaml ; extra == 'all'
Provides-Extra: content_extraction
Requires-Dist: beautifulsoup4 ; extra == 'content_extraction'
Requires-Dist: boilerpy3 ; extra == 'content_extraction'
Provides-Extra: html_parsing
Requires-Dist: html5lib ; extra == 'html_parsing'
Requires-Dist: lxml ; extra == 'html_parsing'
Provides-Extra: mysql
Requires-Dist: pymysql ; extra == 'mysql'
Provides-Extra: postgresql
Requires-Dist: psycopg2 ; extra == 'postgresql'
Provides-Extra: testing
Requires-Dist: pytest ; extra == 'testing'
Requires-Dist: pytest-twisted ; extra == 'testing'
Requires-Dist: python-dotenv ; extra == 'testing'
Requires-Dist: pyyaml ; extra == 'testing'

# Scrachy
Scrachy was primarily developed to provide a flexible cache storage backend for [Scrapy](https://scrapy.org/) that stores its data in a relational database using [SQLAlchemy](https://www.sqlalchemy.org/).
However, it now has several other additional features including middleware for using Selenium to download requests.
It also comes with a downloader middleware that will optionally ignore requests that are already in the cache.

# Install
You can install the latest version from git:

```
>pip install git+https://bitbucket.org/reidswanson/scrachy.git
``` 

or from PyPI:

```
>pip install scrachy
```

# Documentation
A brief guide to minimally using the cache storage engine and the Selenium backend are given below.
For other configuration options and features please see the full documentation on [Read the Docs](https://scrachy.readthedocs.io/en/latest).

## Storage Backend
To (minimally) use the storage backend you simply need to enable caching by adding the following to your `settings.py` file:  
```python
# Enable caching
HTTPCACHE_ENABLED = True

# Set the storage backend to the one provided by Scrachy.
HTTPCACHE_STORAGE = 'scrachy.middleware.httpcache.AlchemyCacheStorage'

# One of the supported SqlAlchemy dialects
SCRACHY_DB_DIALECT = '<database-dialect>'

# The name of the driver (that must be installed as an extra) and used.
SCRACHY_DB_DRIVER = '<database-driver>'

# Options for connecting to the database
SCRACHY_DB_HOST = '<database-hostname>'
SCRACHY_DB_PORT = '<database-port>'
SCRACHY_DB_SCHEMA = <database-schema>
SCRACHY_DB_DATABASE = '<database-name>'
SCRACHY_DB_USERNAME = '<username>'

# Note, do not store this value in the settings file. Use an environment
# variable or python-dotenv.
SCRACHY_DB_PASSWORD = '<password>'

# A dictionary of other connection arguments
SCRACHY_DB_CONNECT_ARGS = {}

# there may be a conflict with the compression middleware. If you encounter
# errors either disable it or move it after the caching middleware.
DOWNLOADER_MIDDLEWARES = {
   ...
   'scrapy.downloadermiddlewares.http.compression.HttpCompressionMiddleware': None,
}
```

# Selenium
There are two Selenium middleware classes provided by Scrachy.
To use them, first add one of them to the `DOWNLOADER_MIDDLEWARES`

```python
DOWNLOADER_MIDDLEWARES = {
    ...
    'scrachy.middleware.selenium.SeleniumMiddleware': 800,  # or AsyncSeleniumMiddleware
    ...
}
```

Then in your spider parsing code use a `SeleniumRequest` instead of a `scrapy.http.Request`.


# License
Scrachy is released using the GNU Lesser General Public License.
See the [LICENSE](LICENSE.md) file for more details.
Files that are adapted or use code from other sources are indicated either at the top of the file or at the location of the code snippet.
Some of these files were adapted from code released under a 3-clause BSD license.
Those files should indicate the original copyright in a comment at the top of the file.
See the [BSD_LICENSE](BSD_LICENSE.md) file for details of this license.
